{
  "name": "Hadoop学习系列(二)",
  "tagline": "在Linux环境下搭建Hadoop伪分布式环境",
  "body": "# 1.配置Linux的环境，为搭建hadoop做准备\r\n  \r\n\r\n  安装前准备软件：\r\n\r\n                  vitual/vox 或者 VMware10\r\n\r\n                  rhel-server-6.3-i383-dvd.iso\r\n\r\n                  jdk-6u24-linux-xxx.bin\r\n\r\n \t\t          hadoop-2.7.3.tar.gz\r\n\r\n  (这里搭建的是最新的版本，由于版本比较新，出现一些问题网上就找不到解决办法，但还是可以安装的)\r\n\r\n  伪分布模式安装步骤：\r\n\r\n                  关闭防火墙 -> 修改ip墙 -> 修改hostname墙 -> 设置ssh自动登录墙 -> 安装jdk墙 -> 安装hadoop\r\n\r\n# 2.hadoop的伪分布安装 \r\n\r\n##   1.设置静态ip：\r\n\r\n\t步骤：在桌面右上角的图标上，右键修改 -> 重启网卡,执行命令 service network restart -> 验证：执行 ifconfig 查看 ip 是否生效\r\n\r\n\t具体操作：\r\n\r\n\t\t (1) root用户登陆，拥有所有权限。进入界面，点击右上角的网络连接图标，右键选择网络编辑\r\n\r\n\t\t（2）选择 System eth0， 点击 编辑(Edit)，跳出的界面上面俩个选项勾上；设置IPv4：Method 选择静态 ip(Manual) Address：ip (在自己的网段里给)，例如 192.168.80.100， 子网掩码：255.255.255.0  网关 (windows下的那个虚拟 IPv4ip, 用 ipconfig 在 cmd 里面查看)，例如 192.168.80.1；点应用；关闭  \r\n\r\n\t\t（3）查看是否成功：开启终端，输入命令 service network restart 使刚才的设置立即生效（应该显示4个ok,如果最后一个不ok,则delete掉System eth0，再 Add 进去，然后按照步骤重新设置）；ifconfig 看看网络设置是否设置成功；查看是否与 windows 在同一个网段中：ping 192.168.80.1 查看是否能ping通，有包就通，在windows的cmd里面，ping 192.168.80.100 是否也通  \r\n\r\n## 2.修改主机名：\r\n\r\n\t修改原因：类似域名，好记，主机名比ip稳定\r\n\r\n\t步骤：修改当前会话中的主机名 -> 修改配置文件中的主机名 -> 把hostname和ip绑定\r\n\r\n    具体操作：\r\n\r\n\t\t(1)用工具  pieTTY 登陆，比在命令行下方便(直接用终端也是可以的)\r\n\r\n\t\t(2)hostname 查看主机名\r\n\r\n\t\t(3)hostname xxx 改变主机名(这里改为了 jxy )\r\n\r\n\t\t(4)验证：查看 hostname是否生效，但是只对当前会话有效，所以需要改配置文件使之永久生效\r\n\r\n\t\t(5)输入命令 vi /etc/sysconfig/network  将hostname改掉，一劳永逸\r\n\r\n\t\t(6)重启机器，查看是否生效： 输入命令 reboot -h now\r\n\r\n\t\t(7)ping 主机名(此时不通)，所以要把主机名(相当于域名)和ip绑定：输入命令 vi /etc/hosts，增加一行 192.168.80.100 xxx(hostname)，再 ping xxx 一下  \r\n\r\n##   3.关闭防火墙 \r\n\r\n\t步骤：\r\n\r\n\t\t(1)不关闭防火墙的时候：输入命令 service iptables status (可以看到很多输出)\r\n\r\n\t\t(2)关闭：输入命令 service iptables stop (可以看到三个ok)\r\n\r\n\t\t(3)验证：输入命令 service iptables status (此时没有输出)\r\n\r\n\t\t(4)关闭防火墙的自动运行:防火墙有可能自动开启，判断是否有自动重启的功能：输入命令 chkconfig --list (列出所有的服务，如果有on，意味着到了某一级别就会自动启动)  \r\n\r\n\t\t(5)过滤服务：输入命令 chkconfig --list | grep iptables ,如果有on，就需要关闭：输入命令  chkconfig iptables off  \r\n\r\n\t\t(6)查看是否关闭：输入命令 chkconfig --list | grep iptables (都显示 off 则搞定)  \r\n\r\n##   4.使用SSH进行免密码登陆\r\n\r\n\t步骤：\r\n\r\n\t\t(1)输入命令 cd ~/.ssh 位于~/.ssh文件夹下，输入命令 ssh-keygen -t rsa 产生秘钥 (rsa为加密算法)\r\n\r\n\t\t(2)ls  (会发现密钥文件)\r\n\r\n\t\t(3)把公钥放入 authorized_keys 文件：cp ~/.ssh/id-rsa.pub ~/.ssh/authorized_keys\r\n\r\n\t\t(4)ls (显示三个文件)\r\n\r\n\t\t(5)验证：输入命令 ssh localhost (显示登陆进去)\r\n\r\n\t\t(6)输入命令 exit (退出终端)\r\n\r\n   \r\n 注意:以上操作均使用root用户登录，不是su root,俩者有差别的\r\n\r\n 在ubuntu里以root用户登录操作\r\n\r\n##   5.安装JDK\r\n\r\n\t步骤：使用 winscp 把 jdk 文件从windows复制到 /usr/local/ 下，解压 -> 修改配置文件\r\n\r\n\t具体操作：\r\n\r\n\t\t(1)将 jdk-6u24-linux-xxx.bin，hadoop-2.7.3.tar.gz 放到 /root/Downloads/ 下\r\n\r\n\t\t(2)复制到 /usr/local/ 下：输入命令 cd /usr/local/ ；输入命令 rm -rf * (强制递归删除全部有的文件)；输入命令 cp /root/Downloads/* . （拷贝到当前目录下)  \r\n\r\n\t\t(3)输入命令 chmod u+x jdk-6u24-linux-xxx.bin (增加执行权限)\r\n\r\n\t\t(4) /usr/local/ 目录下解压： ./jdk-6u24-linux-xxx.bin\r\n\r\n\t\t(5)可以重命名加压后的 jdk... 文件：mv jdk... jdk\r\n\r\n\t\t(6)配置环境文件：输入命令 vi /etc/profile\r\n\r\n\t\t(7)增加 export JAVA_HOME=/usr/local/jdk (刚刚的安装目录) \r\n\r\n                export PATH=.:$JAVA_HOME/bin:$PATH \r\n\r\n                保存退出，让改动立即生效：输入命令 source /etc/profile\r\n\r\n\t\t(8)验证：输入命令 java -version (出现java版本则成功）\r\n\r\n##   6.安装hadoop\r\n\r\n\t具体操作：\r\n\t\t(1)在 /usr/local目录下解压 hadoop-2.7.3.tar.gz ：输入命令 tar -zxvf hadoop-2.7.3.tar.gz ，得到文件 hadoop-2.7.3  \r\n\r\n\t\t(2)重命名：输入命令 mv hadoop-2.7.3.tar.gz hadoop\r\n\r\n\t\t(3)输入命令 vi /etc/profile ，增加一行 export HADOOP_HOME=/usr/local/hadoop \r\n\r\n\t        修改 export PATH=.:$JAVA_HOME/bin:$PATH  为 export PATH=.:$HADOOP_HOME/bin:$JAVA_HOME/bin:$PATH ，保存退出，输入 source /etc/profile  \r\n\r\n\t\t(4)修改配置文件，使适应伪分布，修改位于 $HADOOP_HOME/conf 目录下的 hadoop-env.sh、core-site.xml、hdfs-site.xml、mapred-site.xml 文件，具体如下：\r\n\r\n\t\t`$: vi hadoop-env.sh`\r\n\r\n\t\t`export JAVA_HOME=/usr/local/jdk`\r\n\r\n\t\t$: vi core-site.xml\r\n\r\n\t\t<configuration>\r\n\r\n    \t\t <property>\r\n\r\n   \t\t   <name>fs.defualt.name</name>\r\n\r\n  \t\t   <value>hdfs://hadoop0:9000</value>\r\n\r\n  \t\t   <description>change your own hostname</description>\r\n\r\n \t\t </property>\r\n\r\n \t\t <property>\r\n\r\n  \t\t   <name>hadoop.tmp.dir</name>\r\n\r\n   \t\t   <value>/usr/local/hadoop/tmp</value>\r\n\r\n \t\t </property>\r\n\r\n\t\t</configuration>\r\n\r\n\t\t$: vi hdfs-site.xml\r\n\r\n\t\t<configuration>\r\n\r\n \t\t  <property>\r\n\r\n   \t\t   <name>dfs.replication</name>\r\n\r\n  \t\t   <value>1</value>\r\n\r\n \t\t  </property>\r\n\r\n \t\t  <property>\r\n\r\n  \t\t   <name>dfs.permissions</name>\r\n\r\n  \t\t   <value>false</value>\r\n\r\n\t\t  </property>\r\n\r\n\t\t</configuration>\r\n\r\n\r\n\t\t$: vi mapred-site.xml\r\n\r\n  \t\t<configuration>\r\n\r\n\t\t <property>\r\n\r\n \t\t  <name>mapred.job.tracker</name>\r\n\r\n  \t\t  <value>hadoop0:9001</value>\r\n\r\n  \t\t  <description>change your own hostname</description>\r\n\r\n \t\t </property>\r\n\r\n\t        </configuration>\r\n\r\n    (注意：hadoop0 改为自己的真实主机名）\r\n\r\n\t\t(5)对 hadoop 进行格式化：输入命令 hadoop namenode -format\r\n\r\n\t\t(6)启动：输入命令 start -all.sh (该有5个starting)\r\n\r\n\t\t(7)验证：用 jps 查看java进程 (应该有5个：JobTracker、SecondaryNameNode、DataNode、TaskTracker、Jps、NameNode ；或者：打开火狐浏览器，访问 hadoop：50070 ，能看到 NameNode，说明 NameNode 这个进程活着，在端口 50030 也能看到JobTracker\r\n\r\n\t\t(8)在 windows 的浏览器里输入 hadoop 是无法打开的，因为主机名和ip没有绑定：进入 C:\\Windows\\System32\\driver\\etc 下的 hosts 文件，增加 192.168.80.100 hadoop, 在 windows 下就能访问了，如果还是无法访问，有可能网络是不通的，那么 ping 一下)  \r\n\r\n## PS：安装不成功的常见原因：\r\n\r\n\t(1)NameNode进程没有启动成功：可能没有格式化；配置文件只是copy，没有修改成自己的实际情况；hostname与ip没有绑定；ssh的免密码登陆没有配置成功\r\n\r\n\t(2)多次格式化hadoop也会出错(多个版本不兼容)：方法删除 /usr/local/hadoop/tmp 文件夹，重新格式化\r\n \r\n  \r\n\r\n   \t  \r\n\t\t  ",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}